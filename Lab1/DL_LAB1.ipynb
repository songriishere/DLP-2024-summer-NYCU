{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#產生 linear data\n",
    "def generate_linear(n=100):\n",
    "    pts = np.random.uniform(0, 1,(n, 2))\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for pt in pts:\n",
    "        inputs.append([pt[0], pt[1]])\n",
    "        distance = (pt[0]-pt[1])/1.414\n",
    "        if pt[0] > pt[1]:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    \n",
    "    return np.array(inputs), np.array(labels).reshape(n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#產生 XOR 資料\n",
    "def generate_XOR_easy():\n",
    "    inputs=[]\n",
    "    labels=[]\n",
    "\n",
    "    for i in range(11):\n",
    "        inputs.append([0.1*i, 0.1*i])\n",
    "        labels.append(0)\n",
    "\n",
    "        if (0.1*i == 0.5):        #為了不要生成兩個(0.5,0.5) 且 Label不一樣的情況\n",
    "            continue\n",
    "        \n",
    "        inputs.append([0.1*i, 1-0.1*i])\n",
    "        labels.append(1)\n",
    "\n",
    "    return np.array(inputs),np.array(labels).reshape(21,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(x, y, pred_y):\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('Ground truth', fontsize=20)\n",
    "    for i in range(x.shape[0]):\n",
    "        if y[i] == 0:\n",
    "            plt.plot(x[i][0], x[i][1], 'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0], x[i][1], 'bo')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('Predict result', fontsize=20)\n",
    "    for i in range(x.shape[0]):\n",
    "        if pred_y[i] == 0:\n",
    "            plt.plot(x[i][0], x[i][1], 'ro')\n",
    "        else:\n",
    "            plt.plot(x[i][0], x[i][1], 'bo')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return np.multiply(x, 1.0 - x)\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.where(x > 0, x, 0)\n",
    "\n",
    "def derivative_ReLU(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def MSELoss(y, y_hat):\n",
    "    batch_size = y.shape[0]\n",
    "    distance = np.sum((y-y_hat)**2)\n",
    "    return distance/batch_size, 2*(y - y_hat)/batch_size    #return distance(loss) 和 gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronNetworkLayer:\n",
    "    def __init__(self, input_size, output_size, activate = \"Sigmoid\"):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activate = activate\n",
    "        self.weights_grad = 0\n",
    "        self.bias_grad = 0\n",
    "        self.weight_total = 0\n",
    "        self.bias_total = 0\n",
    "        #weight and bias\n",
    "        self.weight = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(1 , output_size)/100        #為了讓bias不要太大\n",
    "\n",
    "    def forward(self , x):\n",
    "        self.x = x\n",
    "        z = np.dot(x , self.weight) + self.bias\n",
    "        if self.activate == \"Sigmoid\":\n",
    "            z = sigmoid(z)\n",
    "        elif self.activate == \"ReLU\":\n",
    "            z = ReLU(z)\n",
    "        else:\n",
    "            pass\n",
    "        self.z = z\n",
    "        return z\n",
    "    \n",
    "    def backward(self , back_grad , optim = \"SGD\" , lr = 0.1):\n",
    "        if self.activate == \"Sigmoid\" :\n",
    "            grad = back_grad * derivative_sigmoid(self.z)\n",
    "        elif self.activate == \"ReLU\":\n",
    "            grad = back_grad * derivative_ReLU(self.z)\n",
    "        else :\n",
    "            grad = back_grad\n",
    "        \n",
    "        if optim == \"SGD\":\n",
    "            self.weights_grad = np.dot(self.x.T, grad) \n",
    "            self.bias_grad = np.sum(grad) \n",
    "            self.weight -= lr * self.weights_grad\n",
    "            self.bias -= lr * self.bias_grad\n",
    "        elif optim == \"AdaGrad\":\n",
    "            self.weight_total += np.dot(self.x.T , grad) ** 2\n",
    "            self.bias_total += np.sum(grad) ** 2\n",
    "            self.weight -= np.dot(self.x.T, grad) * lr / (np.sqrt(self.weight_total) + 1e-7)\n",
    "            self.bias -= np.sum(grad) * lr / (np.sqrt(self.bias_total) + 1e-7)\n",
    "        return np.dot(grad, self.weight.T)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronNetworkModel:\n",
    "    def __init__(self, input_size = 2 , hidden_size = 10 ,output_size = 1,lr = 0.01, activate = \"Sigmoid\" , \n",
    "                 optim = \"SGD\" , epoch_show = 10000):\n",
    "        self.layer1 = NeuronNetworkLayer(input_size, hidden_size, activate)\n",
    "        self.layer2 = NeuronNetworkLayer(hidden_size, hidden_size, activate)\n",
    "        if activate == \"None\":\n",
    "            self.output = NeuronNetworkLayer(hidden_size,output_size, activate)\n",
    "        else:\n",
    "            self.output = NeuronNetworkLayer(hidden_size,output_size, \"Sigmoid\")   #ReLU不適合輸出 因為[0,infinity)\n",
    "\n",
    "        self.loss=[]\n",
    "        self.lr = lr\n",
    "        self.epoch = 0\n",
    "        self.optim = optim\n",
    "        self.epoch_show = epoch_show\n",
    "    \n",
    "    def train(self , x , y , epoch=100000):\n",
    "        self.epoch += epoch\n",
    "        for i in range (epoch):\n",
    "            output = self.output.forward(self.layer2.forward(self.layer1.forward(x)))\n",
    "            loss , grad = MSELoss(output, y)\n",
    "            self.layer1.backward(self.layer2.backward(self.output.backward(grad,self.optim,self.lr),self.optim,self.lr),self.optim,self.lr)\n",
    "            self.loss.append(loss)\n",
    "\n",
    "            if i % self.epoch_show == 0 :\n",
    "                print(f\"epoch {i} , loss : {loss}\")\n",
    "        self.result = output\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.title(\"Learning Curve\", fontsize = 20)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.plot(self.loss , color = 'orange')\n",
    "        return output\n",
    "\n",
    "    def show_result(self,x,y):\n",
    "        print(\"Test : \")\n",
    "        for i in range(y.size):\n",
    "            print(f\"Iter{i+1} |    Ground truth: {y[i]} |     prediction: {self.result[i]} |\")\n",
    "        print(f\"Accuracy : {sum((self.result > 0.5)== (y==1))/y.size}\\n\")\n",
    "        show_result(x,y,self.result>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY DIFFERENT LEARNING RATE (LINEAR)\n",
    "lr = 0.1 , 0.01 , 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.01)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.001)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY DIFFERENT LEARNING RATE (XOR)\n",
    "lr = 0.1 , 0.01 , 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.01)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.001)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY DIFFERNET NUMBERS OF HIDDEN UNIT (LINEAR)\n",
    "2 , 10 , 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 2, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 50, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY DIFFERNET NUMBERS OF HIDDEN UNIT (XOR)\n",
    "2 , 10 , 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 2, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 50, activate = \"Sigmoid\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY WITHOUT ACTIVATION FUNCTION (LINEAR AND XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"None\", optim = \"SGD\", lr = 0.000001)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"None\", optim = \"SGD\", lr = 0.0001)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENT DIFFERENT ACTIVATION FUNCTION (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"ReLU\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"ReLU\", optim = \"SGD\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " IMPLEMENT DIFFERENT OPTIMIZER (AdaGrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_linear()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"AdaGrad\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "x, y= generate_XOR_easy()\n",
    "model = NeuronNetworkModel(hidden_size = 10, activate = \"Sigmoid\", optim = \"AdaGrad\", lr = 0.1)\n",
    "model.train(x,y,100000)\n",
    "model.show_result(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
